{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea757529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions and callback to display sample prediction\n",
    "# adapted from https://www.tensorflow.org/tutorials/images/segmentation\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']  \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        pred_mask = create_mask(model.predict(sample_image[tf.newaxis, ...]))\n",
    "        display([sample_image, seg2rgb(sample_mask, NUM_CLASSES), seg2rgb(pred_mask, NUM_CLASSES)])\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "\n",
    "def build_unet(n_classes):\n",
    "    \n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    # encoder: contracting; downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "    \n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "    \n",
    "    # decoder: expanding; upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "    \n",
    "    # outputs\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "    \n",
    "    # U-Net model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    \n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b08523",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(x \u001b[38;5;241m=\u001b[39m  X_tr, y \u001b[38;5;241m=\u001b[39m y_tr,\n\u001b[1;32m      4\u001b[0m                           batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      5\u001b[0m                           epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m      6\u001b[0m                           validation_data\u001b[38;5;241m=\u001b[39m(X_te, y_te),\n\u001b[1;32m      7\u001b[0m                           verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      8\u001b[0m                           callbacks\u001b[38;5;241m=\u001b[39m[DisplayCallback()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "\n",
    "model_history = model.fit(x =  X_tr, y = y_tr,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=NUM_EPOCHS,\n",
    "                          validation_data=(X_te, y_te),\n",
    "                          verbose=1,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de211ec8",
   "metadata": {},
   "source": [
    "### sklearn miou\n",
    "requires `run_eagerly=True` in `model.compile()` which increases running time 3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bc39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom loss and metrics\n",
    "\n",
    "# use miou/jaccard score for multiclass segmentation;\n",
    "# our implementation of binary counts as multiclass\n",
    "# because it keeps two separate channels\n",
    "\n",
    "# tensorflow's implementation is here: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU\n",
    "# and here's a callback for the sklearn one but it seems like a lot:\n",
    "# https://keras.io/examples/keras_recipes/sklearn_metric_callbacks/\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def raw_miou(y_true, y_pred):\n",
    "    \"\"\"Returns raw per-class average.\"\"\"\n",
    "    raw_miou = jaccard_score(\n",
    "        y_true=y_true.numpy().flatten(),\n",
    "        y_pred=np.argmax(y_pred.numpy(), axis=-1).flatten(),\n",
    "        average='macro')\n",
    "    return raw_miou\n",
    "\n",
    "def weighted_miou(y_true, y_pred):\n",
    "    \"\"\"Returns weighted average accounting for class imbalance.\"\"\"\n",
    "    weighted_miou = jaccard_score(\n",
    "        y_true=y_true.numpy().flatten(),\n",
    "        y_pred=np.argmax(y_pred.numpy(), axis=-1).flatten(),\n",
    "        average='weighted')\n",
    "    return weighted_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but with tensorflow argmax and flatten\n",
    "\n",
    "def raw_miou(y_true, y_pred):\n",
    "    \"\"\"Returns raw per-class average.\"\"\"\n",
    "    raw_miou = jaccard_score(\n",
    "        y_true=tf.reshape(y_true, [-1]).numpy(),\n",
    "        y_pred=tf.reshape(tf.math.argmax(y_pred, axis=-1), [-1]).numpy(),\n",
    "        average='macro')\n",
    "    return raw_miou\n",
    "\n",
    "def weighted_miou(y_true, y_pred):\n",
    "    \"\"\"Returns weighted average accounting for class imbalance.\"\"\"\n",
    "    weighted_miou = jaccard_score(\n",
    "        y_true=tf.reshape(y_true, [-1]).numpy(),\n",
    "        y_pred=tf.reshape(tf.math.argmax(y_pred, axis=-1), [-1]).numpy(),\n",
    "        average='weighted')\n",
    "    return weighted_miou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa650-final",
   "language": "python",
   "name": "musa650-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
